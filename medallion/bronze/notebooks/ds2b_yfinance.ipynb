{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "450262cf-98da-40c8-b2a2-466ff29fc96f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# WIDGET\n",
    "# ==============================\n",
    "dbutils.widgets.text(\n",
    "    name=\"config_path\",\n",
    "    defaultValue=\"/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/medallion/bronze/yfinance.json\",\n",
    "    label=\"Config File Path\"\n",
    ")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# IMPORTS\n",
    "# =========================\n",
    "import json\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    input_file_name,\n",
    "    current_timestamp,\n",
    "    regexp_extract\n",
    ")\n",
    "\n",
    "from utils.logger import get_logger\n",
    "from utils.sparksession import create_spark_session\n",
    "from utils.schema import YFINANCE_SCHEMA_MAP\n",
    "\n",
    "# =========================\n",
    "# INIT LOGGER & SPARK\n",
    "# =========================\n",
    "logger = get_logger(\"ds2b_yfinance_bronze\")\n",
    "spark = create_spark_session(\"DS2B | YFinance Bronze\")\n",
    "\n",
    "logger.info(\"Spark session initialised\")\n",
    "\n",
    "# =========================\n",
    "# LOAD CONFIG\n",
    "# =========================\n",
    "config_path = dbutils.widgets.get(\"config_path\")\n",
    "logger.info(f\"Loading config from: {config_path}\")\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "CATALOG = config[\"catalog\"]\n",
    "SCHEMA = config[\"schema\"]\n",
    "BASE_PATH = config[\"base_path\"]\n",
    "TABLES = config[\"tables\"]\n",
    "\n",
    "logger.info(\n",
    "    f\"Config loaded | Catalog={CATALOG}, Schema={SCHEMA}, BasePath={BASE_PATH}\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "### \n",
    "\n",
    "import re\n",
    "\n",
    "def clean_column_names(df):\n",
    "    cleaned_cols = []\n",
    "    for c in df.columns:\n",
    "        new_c = c.lower()\n",
    "        new_c = re.sub(r\"[ ,;{}()\\n\\t=]\", \"_\", new_c)\n",
    "        new_c = re.sub(r\"_+\", \"_\", new_c)\n",
    "        new_c = new_c.strip(\"_\")\n",
    "        cleaned_cols.append(new_c)\n",
    "\n",
    "    return df.toDF(*cleaned_cols)\n",
    "# =========================\n",
    "# PROCESS TABLES\n",
    "# =========================\n",
    "for table in TABLES:\n",
    "\n",
    "    table_name = table[\"name\"]\n",
    "    relative_path = table[\"path\"]\n",
    "    file_format = table.get(\"format\", \"csv\")\n",
    "    header = table.get(\"header\", True)\n",
    "    infer_schema = table.get(\"inferSchema\", True)\n",
    "\n",
    "    logger.info(f\"Processing table: {table_name}\")\n",
    "\n",
    "    schema = YFINANCE_SCHEMA_MAP[table_name]\n",
    "\n",
    "    df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .schema(schema)\n",
    "        .option(\"header\", True)\n",
    "        .option(\"mode\", \"PERMISSIVE\")\n",
    "        .load(f\"{BASE_PATH}/{relative_path}/*.csv\")\n",
    "        .withColumn(\"file_path\", col(\"_metadata.file_path\"))\n",
    "        .withColumn(\"last_updated_ts\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Read completed for {table_name}\")\n",
    "\n",
    "    (\n",
    "        df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .saveAsTable(f\"`{CATALOG}`.{SCHEMA}.{table_name}\")\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Written Bronze table: {table_name}\")\n",
    "\n",
    "logger.info(\"DS2B YFinance Bronze pipeline completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd612516-fa32-4e19-8177-32cec4734a3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ds2b_yfinance",
   "widgets": {
    "config_path": {
     "currentValue": "/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/medallion/bronze/yfinance.json",
     "nuid": "f2946976-5c41-46d8-a447-5f7a43832225",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/medallion/bronze/yfinance.json",
      "label": "Config File Path",
      "name": "config_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/medallion/bronze/yfinance.json",
      "label": "Config File Path",
      "name": "config_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
