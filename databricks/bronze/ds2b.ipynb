{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4909ce13-7028-445f-8b1b-2db0cd654dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\n",
    "    name=\"config_path\",\n",
    "    defaultValue=\"/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/databricks/bronze/config.json\",\n",
    "    label=\"Config File Path\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c25d9503-77ba-42db-97c0-f00913b8388f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, regexp_extract, explode, current_timestamp\n",
    "\n",
    "# =========================\n",
    "# LOAD CONFIG\n",
    "# =========================\n",
    "config_path = dbutils.widgets.get(\"config_path\")\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "CATALOG = config[\"catalog\"]\n",
    "SCHEMA = config[\"schema\"]\n",
    "BASE_PATH = config[\"base_path\"]\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS `{CATALOG}`\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS `{CATALOG}`.{SCHEMA}\")\n",
    "\n",
    "# =========================\n",
    "# SCHEMAS MAP\n",
    "# =========================\n",
    "overview_schema = StructType([\n",
    "    StructField(\"company_name\", StringType()),\n",
    "    StructField(\"company_number\", StringType()),\n",
    "    StructField(\"company_status\", StringType()),\n",
    "    StructField(\"date_of_creation\", StringType()),\n",
    "    StructField(\"jurisdiction\", StringType()),\n",
    "    StructField(\"type\", StringType()),\n",
    "    StructField(\"etag\", StringType()),\n",
    "    StructField(\"has_charges\", BooleanType()),\n",
    "    StructField(\"has_insolvency_history\", BooleanType())\n",
    "])\n",
    "\n",
    "officers_schema = StructType([\n",
    "    StructField(\"items\", ArrayType(StructType([\n",
    "        StructField(\"name\", StringType()),\n",
    "        StructField(\"officer_role\", StringType()),\n",
    "        StructField(\"appointed_on\", StringType()),\n",
    "        StructField(\"nationality\", StringType())\n",
    "    ])))\n",
    "])\n",
    "\n",
    "filing_schema = StructType([\n",
    "    StructField(\"items\", ArrayType(StructType([\n",
    "        StructField(\"date\", StringType()),\n",
    "        StructField(\"type\", StringType()),\n",
    "        StructField(\"description\", StringType()),\n",
    "        StructField(\"category\", StringType())\n",
    "    ])))\n",
    "])\n",
    "\n",
    "SCHEMA_MAP = {\n",
    "    \"overview\": overview_schema,\n",
    "    \"officers\": officers_schema,\n",
    "    \"filing_history\": filing_schema\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# PROCESS TABLES\n",
    "# =========================\n",
    "for table in config[\"tables\"]:\n",
    "\n",
    "    table_name = table[\"name\"]\n",
    "    file_name = table[\"file\"]\n",
    "    explode_flag = table.get(\"explode\", False)\n",
    "    explode_column = table.get(\"explode_column\")\n",
    "\n",
    "    print(f\"Processing {table_name}...\")\n",
    "\n",
    "    df = spark.read \\\n",
    "        .schema(SCHEMA_MAP[table_name]) \\\n",
    "        .option(\"multiline\", \"true\") \\\n",
    "        .json(f\"{BASE_PATH}/*/*/*/*/{file_name}\") \\\n",
    "        .withColumn(\"file_path\", col(\"_metadata.file_path\")) \\\n",
    "        .withColumn(\"company_number\",\n",
    "            regexp_extract(\"file_path\", r'/([0-9A-Z]+)/', 1)\n",
    "        )\n",
    "\n",
    "    if explode_flag:\n",
    "        df = df.withColumn(\"exploded\", explode(explode_column)).select(\n",
    "            \"company_number\", \"exploded.*\"\n",
    "        )\n",
    "\n",
    "    df = df.withColumn(\"last_updated_ts\", current_timestamp())\n",
    "\n",
    "    df.write \\\n",
    "        .format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .saveAsTable(f\"`{CATALOG}`.{SCHEMA}.{table_name}\")\n",
    "\n",
    "print(\"Metadata-Driven Bronze Pipeline Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cae3071-a44d-48f2-802f-9a0b0c6ace8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_raw = spark.read.text(config_path).collect()[0][0]\n",
    "print(config_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c993af0-d088-4f12-9b7e-543be1304657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ds2b",
   "widgets": {
    "config_path": {
     "currentValue": "/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/databricks/bronze/config.json",
     "nuid": "a9d25557-5682-4e79-9e8b-ba20038e6ade",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/databricks/bronze/config.json",
      "label": "Config File Path",
      "name": "config_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Workspace/Users/ud3041@gmail.com/end-to-end-ETL-pipeline/databricks/bronze/config.json",
      "label": "Config File Path",
      "name": "config_path",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
